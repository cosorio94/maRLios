{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros import SuperMarioBrosEnv\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import gym\n",
    "import numpy as np\n",
    "import collections \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from toolkit.gym_env import *\n",
    "from toolkit.action_utils import *\n",
    "import pandas as pd # here if you need it\n",
    "\n",
    "# models CHANGE FOR YOUR MODEL\n",
    "from toolkit.train_marlios_rnn import make_env #NOTE your make env may not be here\n",
    "from toolkit.marlios_rnn import *\n",
    "##################################\n",
    "\n",
    "from toolkit.constants import *\n",
    "from toolkit.train_test_samples import *\n",
    "import warnings\n",
    "from toolkit.statistics import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [28:11<05:26, 14.20s/it]"
     ]
    }
   ],
   "source": [
    "# create the environment (don't change)\n",
    "mario_env='SuperMarioBros-1-1-v0'\n",
    "env = gym.make(mario_env)\n",
    "env = make_env(env, ACTION_SPACE) # (this is defined in my train_marlios_rnn.py, make sure you import yours)\n",
    "\n",
    "####################\n",
    "# load the agent (change depending on your model architecture)\n",
    "agent = DQNAgent(\n",
    "                state_space=env.observation_space.shape,\n",
    "                action_space=TEST_SET, #NOTE CHANGE THIS depending on the stats you track\n",
    "                gamma=0.9,\n",
    "                max_memory_size=3000, # this doesnt matter here\n",
    "                batch_size=64, # this doesnt matter here\n",
    "                lr=0,\n",
    "                dropout=None,\n",
    "                exploration_max=0,\n",
    "                exploration_min=0,\n",
    "                exploration_decay=0.9995,\n",
    "                double_dq=True,\n",
    "                pretrained=True,\n",
    "                run_id='marlios_rnn_test', #NOTE CHANGE THIS\n",
    "                n_actions=64,  \n",
    "                training_stage='test', # your model may not have this parameter, make sure if you're running the rnn its 'train', 'test' or 'val' depending on action space\n",
    "                device='cpu', # probably fine to leave this\n",
    "                add_sufficient=True, # your action utils may not require this (or your model)\n",
    "                hidden_shape=64 # must be the same for what we trained the model on (can reference wandb)\n",
    "                )\n",
    "\n",
    "# setup lists of stats we are tracking\n",
    "num_episodes = 100\n",
    "total_rewards = []\n",
    "x_position = []\n",
    "flags_got, pipe2, pipe3, pipe4 = 0, 0, 0, 0\n",
    "\n",
    "for ep in tqdm(range(num_episodes)):\n",
    "    stats = get_stats_run(agent, env) #NOTE: my validate run is coming from statistics.py\n",
    "    total_rewards.append(stats['total_reward'])\n",
    "    x_position.append(stats['x_pos'])\n",
    "    flags_got += stats['flag_get']\n",
    "    pipe2 += stats['pipe2']\n",
    "    pipe3 += stats['pipe3']\n",
    "    pipe4 +=  stats['pipe4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(training_stage, total_rewards, x_position, flags, pipes, num_episodes):\n",
    "    pipe2, pipe3, pipe4 = pipes\n",
    "\n",
    "    avg_total_rewards = np.mean(total_rewards)\n",
    "    stddev_rewards = np.std(total_rewards)\n",
    "\n",
    "    avg_xpos = np.mean(x_position)\n",
    "    stddev_xpos = np.mean(x_position)\n",
    "\n",
    "    print(\"Statistics for \", training_stage)\n",
    "    print(f\"Avg Total Rewards: {avg_total_rewards:.3f}\")\n",
    "    print(f\"Std Dev Rewards: {stddev_rewards:.3f}\")\n",
    "    print(f\"# of Wins: {flags_got}\")\n",
    "    print(f\"% Pipe 1 {pipe2/num_episodes:.3f}\")\n",
    "    print(f\"% Pipe 2 {pipe3/num_episodes:.3f}\")\n",
    "    print(f\"% Pipe 3 {pipe4/num_episodes:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics(training_stage=\"TEST (holdout)\", \n",
    "                 total_rewards=total_rewards,\n",
    "                 x_position=x_position,\n",
    "                 flags=flags_got,\n",
    "                 pipes=(pipe2, pipe3, pipe4)\n",
    "                 num_episodes=num_episodes\n",
    "                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
