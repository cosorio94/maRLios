{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros import SuperMarioBrosEnv\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import gym\n",
    "import numpy as np\n",
    "import collections \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from toolkit.gym_env import *\n",
    "from toolkit.action_utils import *\n",
    "# import pandas as pd # here if you need it\n",
    "\n",
    "# models CHANGE FOR YOUR MODEL\n",
    "from toolkit.train_marlios_carlos import make_env #NOTE your make env may not be here\n",
    "from toolkit.marlios_model_carlos import *\n",
    "##################################\n",
    "\n",
    "from toolkit.constants import *\n",
    "from toolkit.train_test_samples import *\n",
    "import warnings\n",
    "from toolkit.statistics import *\n",
    "import toolkit.action_utils_carlos as action_utils\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:42:58<00:00, 61.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# create the environment (don't change)\n",
    "mario_env='SuperMarioBros-1-1-v0'\n",
    "env = gym.make(mario_env)\n",
    "env = make_env(env, ACTION_SPACE) # (this is defined in my train_marlios_rnn.py, make sure you import yours)\n",
    "\n",
    "####################\n",
    "# load the agent (change depending on your model architecture)\n",
    "agent = DQNAgent(\n",
    "                state_space=env.observation_space.shape,\n",
    "                action_space=TEST_SET, #NOTE CHANGE THIS depending on the stats you track\n",
    "                gamma=0.9,\n",
    "                max_memory_size=3000, # this doesnt matter here\n",
    "                batch_size=64, # this doesnt matter here\n",
    "                lr=0,\n",
    "                dropout=None,\n",
    "                exploration_max=0,\n",
    "                exploration_min=0,\n",
    "                exploration_decay=0.9995,\n",
    "                double_dq=True,\n",
    "                pretrained=True,\n",
    "                run_id='marlios_run_baselike_cnn_power_sample_ep_lr_0_001', #NOTE CHANGE THIS\n",
    "                n_actions=64,  \n",
    "                mode=action_utils.TEST, # your model may not have this parameter, make sure if you're running the rnn its 'train', 'test' or 'val' depending on action space\n",
    "                # device='cpu', # probably fine to leave this\n",
    "                sample_actions=True, # your action utils may not require this (or your model)\n",
    "                # hidden_shape=64 # must be the same for what we trained the model on (can reference wandb)\n",
    "                )\n",
    "\n",
    "# setup lists of stats we are tracking\n",
    "num_episodes = 100\n",
    "total_rewards = []\n",
    "x_position = []\n",
    "flags_got, pipe2, pipe3, pipe4 = 0, 0, 0, 0\n",
    "\n",
    "for ep in tqdm(range(num_episodes)):\n",
    "    stats = get_stats_run(agent, env) #NOTE: my validate run is coming from statistics.py\n",
    "    total_rewards.append(stats['total_reward'])\n",
    "    x_position.append(stats['x_pos'])\n",
    "    flags_got += stats['flag_get']\n",
    "    pipe2 += stats['pipe2']\n",
    "    pipe3 += stats['pipe3']\n",
    "    pipe4 +=  stats['pipe4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(training_stage, total_rewards, x_position, flags, pipes, num_episodes):\n",
    "    pipe2, pipe3, pipe4 = pipes\n",
    "\n",
    "    avg_total_rewards = np.mean(total_rewards)\n",
    "    stddev_rewards = np.std(total_rewards)\n",
    "\n",
    "    avg_xpos = np.mean(x_position)\n",
    "    stddev_xpos = np.mean(x_position)\n",
    "\n",
    "    print(\"Statistics for \", training_stage)\n",
    "    print(f\"Avg Total Rewards: {avg_total_rewards:.3f}\")\n",
    "    print(f\"Std Dev Rewards: {stddev_rewards:.3f}\")\n",
    "    print(f\"# of Wins: {flags_got}\")\n",
    "    print(f\"% Pipe 1 {pipe2/num_episodes:.3f}\")\n",
    "    print(f\"% Pipe 2 {pipe3/num_episodes:.3f}\")\n",
    "    print(f\"% Pipe 3 {pipe4/num_episodes:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for  TEST (holdout)\n",
      "Avg Total Rewards: 223.660\n",
      "Std Dev Rewards: 214.674\n",
      "# of Wins: 0\n",
      "% Pipe 1 0.190\n",
      "% Pipe 2 0.070\n",
      "% Pipe 3 0.010\n"
     ]
    }
   ],
   "source": [
    "print_statistics(training_stage=\"TEST (holdout)\", \n",
    "                 total_rewards=total_rewards,\n",
    "                 x_position=x_position,\n",
    "                 flags=flags_got,\n",
    "                 pipes=(pipe2, pipe3, pipe4),\n",
    "                 num_episodes=num_episodes\n",
    "                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
